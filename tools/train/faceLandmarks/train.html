<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="commons.js"></script>
  <script src="js/imageToSquare.js"></script>
  <script src="js/randomCrop.js"></script>
  <script src="FileSaver.js"></script>
</head>
<body>
  <div id="container"></div>

  <script>
    tf = faceapi.tf

    // uri to weights file of last checkpoint
    const modelCheckpoint = '/tmp/landmarks_epoch23_rc_e26.weights'
    const startEpoch = 24

    const learningRate = 0.00001 // 0.001
    window.optimizer = tf.train.adam(learningRate, 0.9, 0.999, 1e-8)

    window.saveEveryNthSample = Infinity

    window.withRandomCrop = true

    window.batchSize = 16

    window.lossValue = 0

    window.drawResults = true

    const log = (str, ...args) => console.log(`[${[(new Date()).toTimeString().substr(0, 8)]}] ${str || ''}`, ...args)

    function saveWeights(net, filename = 'train_tmp') {
      saveAs(new Blob([net.serializeParams()]), filename)
    }

    async function loadNetWeights(uri) {
      return new Float32Array(await (await fetch(uri)).arrayBuffer())
    }

    async function fetchTrainDataFilenames() {
      return fetch('/face_landmarks_train_filenames').then(res => res.json())
    }

    async function load() {
      window.ptsFiles = await fetchTrainDataFilenames()

      window.net = new faceapi.FaceLandmark68MobileNet()
      const weights = await loadNetWeights(modelCheckpoint)
      await window.net.load(weights)
      window.net.variable()
    }

    async function train() {
      await load()

      for (let epoch = startEpoch; epoch < Infinity; epoch++) {

        if (epoch !== startEpoch) {
          saveWeights(window.net, `landmarks_epoch${epoch - 1}_rc_e26.weights`)
          saveAs(new Blob([JSON.stringify({ loss: window.lossValue, avgLoss: window.lossValue / window.ptsFiles.length })]), `landmarks_epoch${epoch - 1}_rc_e26.json`)
          window.lossValue = 0
        }

        const shuffledInputs = window.drawResults ? window.ptsFiles : faceapi.shuffleArray(window.ptsFiles)

        for (let dataIdx = 0; dataIdx < shuffledInputs.length; dataIdx += window.batchSize) {
          const tsIter = Date.now()

          const ptsFiles = shuffledInputs.slice(dataIdx, dataIdx + window.batchSize)

          // fetch image and ground truth bounding boxes
          const batchData = await Promise.all(
            ptsFiles.map(async ptsFile => {
              const img = await faceapi.bufferToImage(await fetchImage(ptsFile.replace('.json', '.jpg')))
              const pts = await (await fetch(ptsFile)).json()
              return { img, pts }
            })
          )

          const bImages = []
          const bPts = []

          for (let batchIdx = 0; batchIdx < window.batchSize; batchIdx += 1) {

            const batch = batchData[batchIdx]

            if (!batch) {
              continue
            }

            const { img, pts } = batch

            const { croppedImage, shiftedPts } = window.withRandomCrop
              ? randomCrop(img, pts)
              : { croppedImage: img, shiftedPts: pts }

            const squaredImg = imageToSquare(croppedImage, 112, true)

            const reshapedDimensions = faceapi.computeReshapedDimensions(croppedImage, 112)

            const pad = Math.abs(reshapedDimensions.width - reshapedDimensions.height) /  (2 * 112)
            const padX = reshapedDimensions.width < reshapedDimensions.height ? pad : 0
            const padY = reshapedDimensions.height < reshapedDimensions.width ? pad : 0

            const groundTruthLandmarks = shiftedPts.map(pt => new faceapi.Point(
              padX + (pt.x / croppedImage.width) * (reshapedDimensions.width / 112),
              padY + (pt.y / croppedImage.height)* (reshapedDimensions.height / 112)
            ))

            bImages.push(squaredImg)
            bPts.push(groundTruthLandmarks)
          }

          const netInput = await faceapi.toNetInput(bImages)

          const ts = Date.now()

          const loss = optimizer.minimize(() => {
            const out = window.net.runNet(netInput)

            const landmarksTensor = tf.tensor2d(
              bPts
                .reduce((flat, arr) => flat.concat(arr))
                .map(pt => [pt.x, pt.y])
                .reduce((flat, arr) => flat.concat(arr)),
              [window.batchSize, 136]
            )

            const loss = tf.losses.meanSquaredError(
              landmarksTensor,
              out
            )

            return tf.sum(loss)
          }, true)

          const lossValue = loss.dataSync()[0]
          window.lossValue += lossValue
          log(`trainStep time for epoch ${epoch}, dataIdx ${dataIdx}, loss: ${lossValue}, backprop: ${Date.now() - ts} ms, iter: ${Date.now() - tsIter} ms`)
          netInput.dispose()
          loss.dispose()

          await tf.nextFrame()
        }
      }
    }

  </script>
</body>
</html>